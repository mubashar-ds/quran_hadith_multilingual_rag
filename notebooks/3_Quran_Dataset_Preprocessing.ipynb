{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1 - Quran Dataset Preprocessing**"
      ],
      "metadata": {
        "id": "OIA1xJxr5A2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 - Normalized Quranic Text**"
      ],
      "metadata": {
        "id": "WvSrpgAyL9Jq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XwSPt7zQRCzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "text_file = '/content/1_Quran_arabic_tanzil.txt'\n",
        "output_file = '/content/2_Quran_normalized_arabic.json'\n",
        "\n",
        "data = []\n",
        "\n",
        "with open(text_file, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        parts = line.split('|')\n",
        "\n",
        "        if len(parts) < 3:\n",
        "            continue\n",
        "\n",
        "        surah = int(parts[0])\n",
        "        ayah = int(parts[1])\n",
        "        text = '|'.join(parts[2:])\n",
        "\n",
        "        data.append({\n",
        "            \"surah\": surah,\n",
        "            \"ayah\": ayah,\n",
        "            \"text\": text\n",
        "        })\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Conversion completed! JSON saved to:\", output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_PxnpoVL3G-",
        "outputId": "57d64f05-d85e-41d3-a1ee-305358e6bab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion completed! JSON saved to: /content/Quran_normalized_arabic.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ExSlc4bREYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def add_quran_id(input_path: str, output_path: str):\n",
        "\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for idx, rec in enumerate(data, start=1):\n",
        "        rec[\"quran_id\"] = idx\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Added quran_id (1..{len(data)}) and saved → {output_path}\")\n",
        "\n",
        "input_path = \"/content/2_Quran_normalized_arabic.json\"\n",
        "output_path = \"/content/3_Quran_normalized_arabic_with_ids.json\"\n",
        "\n",
        "add_quran_id(input_path, output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwAm-S3BL23g",
        "outputId": "7941c6fb-1772-4ab1-ac52-b8794a19f92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added quran_id (1..6236) and saved → /content/Quran_normalized_arabic_with_ids.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5QepifbNRFsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "input_raw = \"/content/3_Quran_normalized_arabic_with_ids.json\"\n",
        "output_fixed = \"/content/4_Quran_normalized_arabic_final.json\"\n",
        "\n",
        "BISMILLAH_PREFIX_RE = re.compile(\n",
        "    r\"^بسم الله الرحمن الرحيم[ \\u200c\\u200f\\u200e،,:;ـ\\-–—]*\"\n",
        ")\n",
        "\n",
        "def strip_prefixed_bismillah(records):\n",
        "    fixed = []\n",
        "    for rec in records:\n",
        "        surah = rec.get(\"surah_id\") or rec.get(\"surah\")\n",
        "        ayah = rec.get(\"ayah_id\") or rec.get(\"ayah\")\n",
        "        text = rec.get(\"text\") or rec.get(\"text_ar\") or \"\"\n",
        "\n",
        "        if surah is not None and ayah is not None:\n",
        "            if surah >= 2 and ayah == 1:\n",
        "                new_text = BISMILLAH_PREFIX_RE.sub(\"\", text).strip()\n",
        "\n",
        "                if not new_text:\n",
        "                    print(f\"[WARN] Surah {surah} Ayah {ayah}: stripping Bismillah removed all text, keeping original.\")\n",
        "                    new_text = text\n",
        "\n",
        "                if \"text\" in rec:\n",
        "                    rec[\"text\"] = new_text\n",
        "                elif \"text_ar\" in rec:\n",
        "                    rec[\"text_ar\"] = new_text\n",
        "\n",
        "        fixed.append(rec)\n",
        "\n",
        "    return fixed\n",
        "\n",
        "with open(input_raw, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "fixed_data = strip_prefixed_bismillah(data)\n",
        "\n",
        "for rec in fixed_data:\n",
        "    if rec.get(\"surah_id\") == 2 and rec.get(\"ayah_id\") == 1:\n",
        "        print(\"Surah 2, Ayah 1 after fix:\", rec.get(\"text\") or rec.get(\"text_ar\"))\n",
        "        break\n",
        "\n",
        "with open(output_fixed, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(fixed_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Saved cleaned Quran to:\", output_fixed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XORbwURL21J",
        "outputId": "7422f925-526a-4a06-85e0-a80341dc0cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cleaned Quran to: /content/Quran_normalized_arabic_final.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IThwa8_rPgWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Quran Urdu & English Normalization**"
      ],
      "metadata": {
        "id": "OB9yKSLLROgG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UlL-tONIRCAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install camel-tools\n",
        "!pip install pyarabic\n",
        "!pip install clean-text\n",
        "!pip install ftfy\n",
        "!pip install unidecode --quiet\n",
        "\n",
        "import re\n",
        "import json\n",
        "import unicodedata\n",
        "\n",
        "from camel_tools.utils.dediac import dediac_ar\n",
        "from pyarabic import araby\n",
        "from cleantext import clean\n",
        "from ftfy import fix_text\n"
      ],
      "metadata": {
        "id": "fgl2byAnGINB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = \"/content/3_Al_Quran_Dataset_FINAL.json\"\n",
        "output_dataset = \"/content/5_Quran_normalized_ur_en.json\"\n"
      ],
      "metadata": {
        "id": "1ey80KDNRgPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "URDU_PUNCT_RE = re.compile(r\"[،۔؛؟!,:;]\")\n",
        "\n",
        "DIACRITICS_RE = re.compile(r\"[\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]\")\n",
        "\n",
        "URDU_MAP = {\n",
        "    \"ي\": \"ی\",\n",
        "    \"ى\": \"ی\",\n",
        "    \"ئ\": \"ی\",\n",
        "    \"ؤ\": \"و\",\n",
        "    \"ك\": \"ک\",\n",
        "    \"ھ\": \"ہ\",\n",
        "    \"ة\": \"ہ\",\n",
        "}\n",
        "\n",
        "# Remove anything not Urdu script, Arabic script, digits, or whitespace..\n",
        "NON_URDU_ALLOWED = re.compile(r\"[^\\u0600-\\u06FF0-9\\s]\")\n",
        "\n",
        "\n",
        "def normalize_urdu(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    # Unicode normalize\n",
        "    t = unicodedata.normalize(\"NFC\", text)\n",
        "\n",
        "    # 1) Orthographic replacements\n",
        "    for src, tgt in URDU_MAP.items():\n",
        "        t = t.replace(src, tgt)\n",
        "\n",
        "    # 2) Remove diacritics\n",
        "    t = DIACRITICS_RE.sub(\"\", t)\n",
        "\n",
        "    # 3) Remove Urdu punctuation\n",
        "    t = URDU_PUNCT_RE.sub(\" \", t)\n",
        "\n",
        "    # 4) Remove tatweel\n",
        "    t = t.replace(\"ـ\", \"\")\n",
        "\n",
        "    # 5) Remove non-Urdu characters except whitespace/digits\n",
        "    t = NON_URDU_ALLOWED.sub(\" \", t)\n",
        "\n",
        "    # 6) Collapse spaces\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "    return t\n"
      ],
      "metadata": {
        "id": "ORBm9AYJTYLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def normalize_english(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    t = fix_text(text)\n",
        "    t = clean(\n",
        "        t,\n",
        "        lower=True,\n",
        "        fix_unicode=True,\n",
        "        no_urls=True,\n",
        "        no_punct=True,\n",
        "        no_emoji=True,\n",
        "        no_digits=False,\n",
        "    )\n",
        "\n",
        "    return re.sub(r\"\\s+\", \" \", t).strip()\n"
      ],
      "metadata": {
        "id": "aRF41DSfUCdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def enrich_record(item: dict) -> dict:\n",
        "    return {\n",
        "        \"quran_id\": item[\"quran_id\"],\n",
        "        \"juz\": item[\"juz\"],\n",
        "        \"surah_id\": item[\"surah_id\"],\n",
        "        \"ayah_id\": item[\"ayah_id\"],\n",
        "        \"source\": item[\"source\"],\n",
        "        \"transliteration\": item[\"transliteration\"],\n",
        "        \"surah_name_ar\": item[\"surah_name_ar\"],\n",
        "        \"surah_name_ur\": item[\"surah_name_ur\"],\n",
        "        \"surah_name_en\": item[\"surah_name_en\"],\n",
        "        \"surah_type\": item[\"surah_type\"],\n",
        "\n",
        "        \"text_ar\": item[\"text_ar\"],\n",
        "        \"normalized_ur\": normalize_urdu(item.get(\"text_ur\", \"\")),\n",
        "        \"normalized_en\": normalize_english(item.get(\"text_en\", \"\")),\n",
        "    }"
      ],
      "metadata": {
        "id": "fS3JdGtzT4sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_dataset(path: str):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = f.read().strip()\n",
        "\n",
        "    data = []\n",
        "\n",
        "    if raw.startswith(\"[\"):\n",
        "        data = json.loads(raw)\n",
        "    else:\n",
        "        for line in raw.splitlines():\n",
        "            if line.strip():\n",
        "                data.append(json.loads(line))\n",
        "\n",
        "    return [enrich_record(rec) for rec in data]\n",
        "\n",
        "def save_preprocessed_json(records, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\nSaved JSON dataset to {output_path}\")\n",
        "\n",
        "processed_data = load_and_preprocess_dataset(raw_dataset)\n",
        "save_preprocessed_json(processed_data, output_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrUfFKeaU6m6",
        "outputId": "bd3b5fd9-de65-475a-88b5-fb0005f92a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved JSON dataset to /content/Quran_normalized_ur_en.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AWNp9w-4UH0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Merging Normalized Arabic with Normalized Urdu and English**"
      ],
      "metadata": {
        "id": "KL8ib2wXZwhx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aTnXOM65e1UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data_ur_en = \"/content/5_Quran_normalized_ur_en.json\"\n",
        "data_ar = \"/content/4_Quran_normalized_arabic_final.json\"\n",
        "output_full = \"/content/6_Quran_Dataset_preprocessed_full.jsonl\"\n",
        "\n",
        "with open(data_ur_en, \"r\", encoding=\"utf-8\") as f:\n",
        "    ur_en = json.load(f)\n",
        "\n",
        "with open(data_ar, \"r\", encoding=\"utf-8\") as f:\n",
        "    ar_only = json.load(f)\n",
        "\n",
        "ar_map = {item[\"quran_id\"]: item[\"text\"] for item in ar_only}\n",
        "\n",
        "missing_ids = []\n",
        "\n",
        "with open(output_full, \"w\", encoding=\"utf-8\") as out:\n",
        "\n",
        "    for rec in ur_en:\n",
        "        qid = rec[\"quran_id\"]\n",
        "\n",
        "        rec.pop(\"text_ar\", None)\n",
        "\n",
        "        if qid in ar_map:\n",
        "            rec[\"normalized_ar\"] = ar_map[qid]\n",
        "        else:\n",
        "            rec[\"normalized_ar\"] = \"\"\n",
        "            missing_ids.append(qid)\n",
        "\n",
        "        out.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"JSONL merged successfully → {output_full}\")\n",
        "print(\"Missing Arabic quran_ids:\", missing_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox9o03UQc6gz",
        "outputId": "e8e67acd-005b-4ea8-fc66-4048806cf23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSONL merged successfully → /content/Quran_Dataset_preprocessed_full.jsonl\n",
            "Missing Arabic quran_ids: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HP39XLKHZv-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "INPUT = \"/content/6_Quran_Dataset_preprocessed_full.jsonl\"\n",
        "OUTPUT = \"/content/7_Quran_Preprocessed_FINAL.jsonl\"\n",
        "\n",
        "def reformat_record(rec):\n",
        "    return {\n",
        "        \"quran_id\": rec[\"quran_id\"],\n",
        "        \"juz\": rec[\"juz\"],\n",
        "        \"surah_id\": rec[\"surah_id\"],\n",
        "        \"ayah_id\": rec[\"ayah_id\"],\n",
        "        \"source\": rec[\"source\"],\n",
        "\n",
        "        \"transliteration\": rec[\"transliteration\"],\n",
        "        \"surah_name_ar\": rec[\"surah_name_ar\"],\n",
        "        \"surah_name_ur\": rec[\"surah_name_ur\"],\n",
        "        \"surah_name_en\": rec[\"surah_name_en\"],\n",
        "        \"surah_type\": rec[\"surah_type\"],\n",
        "\n",
        "        \"normalized_ar\": rec[\"normalized_ar\"],\n",
        "        \"normalized_ur\": rec[\"normalized_ur\"],\n",
        "        \"normalized_en\": rec[\"normalized_en\"],\n",
        "    }\n",
        "\n",
        "output_file = open(OUTPUT, \"w\", encoding=\"utf-8\")\n",
        "\n",
        "with open(INPUT, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        rec = json.loads(line)\n",
        "        new_rec = reformat_record(rec)\n",
        "        output_file.write(json.dumps(new_rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "output_file.close()\n",
        "print(\"Saved reformatted file →\", OUTPUT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqMLjiTRjtnx",
        "outputId": "ad8f9d6e-57b3-41b1-e818-a63affdc0175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved reformatted file → /content/Quran_Preprocessed_FINAL.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gC7llCGdjuO7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}